<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Collaborative Writing on Tsaiの南極洲</title>
        <link>https://tsairongfu.github.io/zh-tw/tags/collaborative-writing/</link>
        <description>Recent content in Collaborative Writing on Tsaiの南極洲</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-tw</language>
        <lastBuildDate>Sat, 30 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://tsairongfu.github.io/zh-tw/tags/collaborative-writing/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>通訊網路與多媒體應用</title>
        <link>https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/</link>
        <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
        
        <guid>https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/</guid>
        <description>&lt;img src="https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/picture.jpg" alt="Featured image of post 通訊網路與多媒體應用" /&gt;&lt;h2 id=&#34;第3週基礎多媒體網路通訊&#34;&gt;第3週：基礎多媒體網路通訊&lt;/h2&gt;
&lt;h3 id=&#34;homework1&#34;&gt;HomeWork1&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/3sIUu0L.png&#34;
	width=&#34;1022&#34;
	height=&#34;627&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/3sIUu0L_hu7ada9fbe35a80907a517c28cceb3fefa_431610_480x0_resize_box_3.png 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/3sIUu0L_hu7ada9fbe35a80907a517c28cceb3fefa_431610_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;162&#34;
		data-flex-basis=&#34;391px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;多媒體有什麼特性&#34;&gt;多媒體有什麼特性？&lt;/h4&gt;
&lt;p&gt;媒體技術具有的特性包括：多樣性、集成性、交互性
在資料傳輸需求上，會因資料不同而相異&lt;/p&gt;
&lt;h4 id=&#34;在傳輸多媒體時有什麼特別的需求&#34;&gt;在傳輸多媒體時有什麼特別的需求？&lt;/h4&gt;
&lt;p&gt;需要利用網路傳輸，為了避免資料傳輸量過大造成負擔以及提高電腦儲存量，需要進行資料壓縮，且不同形式的多媒體（圖片、影片、聲音）也擁有各種不同的協議。&lt;/p&gt;
&lt;h4 id=&#34;請舉列周圍環境中可以稱之為多媒體通訊的資訊服務與設備&#34;&gt;請舉列周圍環境中，可以稱之為多媒體通訊的資訊服務與設備：&lt;/h4&gt;
&lt;p&gt;我認為現在普遍最常用的就是超商的ibon機器，進行列印、繳費、儲值、購票等都十分方便。再來應該就是目前隨身攜帶的智慧型手機，裡面可以進行各種不同的資訊服務功能。&lt;/p&gt;
&lt;h4 id=&#34;任選一種多媒體通訊的應用搜集相關資料並說明其發展現況及未來趨勢&#34;&gt;任選一種多媒體通訊的應用，搜集相關資料，並說明其發展現況及未來趨勢&lt;/h4&gt;
&lt;p&gt;無線感測網路的應用:舉例來說，像是RFID、ZigBee的發展現況是應用在無線嵌入式（感測）網路或物流供應鏈管理系統上，未來趨勢以業者來說會更加去針對將收集到的資料在供應鏈管理系統中的處理與分佈、以及與資料安全相關的技術開發、感測訊號的辨識和篩選、與後端資料庫伺服器的溝通等等的技術去做精進。&lt;/p&gt;
&lt;h4 id=&#34;視訊會議系統對於遠距教學會有什麼樣的影響列舉視訊會議系統其他可能的用途&#34;&gt;視訊會議系統對於遠距教學，會有什麼樣的影響？列舉視訊會議系統其他可能的用途：&lt;/h4&gt;
&lt;p&gt;我認為視訊會議系統對於遠距教學的影響，一定是正向的。它使得教師能夠更便於管理學生動態，也擁有完整的留言板、視訊功能，能夠一定程度地將實體上課的模式移植到線上遠距教學。&lt;/p&gt;
&lt;p&gt;視訊會議的其他用途，我認為現在網路的進步，已經不像過去要團聚，必須耗費大量時間去移動，雖然會缺少一部分實際見面的感覺，但像目前疫情嚴峻的時期，它一定程度的減緩了人與人之間極需見面的社交需求，達到安定人心的作用。&lt;/p&gt;
&lt;h4 id=&#34;試由網路上找尋和多媒體通訊相關的標準&#34;&gt;試由網路上找尋和多媒體通訊相關的標準。&lt;/h4&gt;
&lt;p&gt;常見的多媒體標準壓縮技術:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;JPEG&lt;/li&gt;
&lt;li&gt;MPEG-1&lt;/li&gt;
&lt;li&gt;MPEG-2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;電腦使用的無線網路標準:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一代，以IEEE 802.11原始標準為準，工作頻段為2.4GHz&lt;/li&gt;
&lt;li&gt;第二代，以IEEE 802.11b為準，工作頻段為2.4GHz&lt;/li&gt;
&lt;li&gt;第三代，以IEEE 802.11a為準，工作頻段為5GHz&lt;/li&gt;
&lt;li&gt;第四代，以IEEE 802.11n為準，世代名稱為「Wi-Fi 4」，信道寬度20MHz、40MHz，工作頻段為2.4GHz和5GHz&lt;/li&gt;
&lt;li&gt;第五代，以IEEE 802.11ac為準，世代名稱為「Wi-Fi 5」，信道寬度20MHz、40MHz、80MHz、80+ 80MHz、160MHz，工作頻段為5GHz&lt;/li&gt;
&lt;li&gt;第六代，以IEEE 802.11ax為準，世代名稱為「Wi-Fi 6」，信道寬度20MHz、40MHz、80MHz、80+ 80MHz、160MHz，工作頻段為2.4GHz和5GHz&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;短距離傳輸所設計的無線通訊標準:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;bluetooth&lt;/li&gt;
&lt;li&gt;ZigBee&lt;/li&gt;
&lt;li&gt;RFID&lt;/li&gt;
&lt;li&gt;IrDA&lt;/li&gt;
&lt;li&gt;UWB&lt;/li&gt;
&lt;li&gt;WiMedia&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;homework2&#34;&gt;HomeWork2&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/mzCoHSu.png&#34;
	width=&#34;1073&#34;
	height=&#34;634&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/mzCoHSu_hu3ff50a51e7ea31c95fbaaee1be057a09_406660_480x0_resize_box_3.png 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/mzCoHSu_hu3ff50a51e7ea31c95fbaaee1be057a09_406660_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;406px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;試說明串流在多媒體的應用中有什麼樣的優點&#34;&gt;試說明串流在多媒體的應用中有什麼樣的優點？&lt;/h4&gt;
&lt;p&gt;串流指的是將一連串影像壓縮，穩定快速的傳送到用戶端，利用協議開啟時，可以不用在用戶端留存檔案，節省空間。&lt;/p&gt;
&lt;h4 id=&#34;請說明單點播送與群播網路寬頻上的運用有什麼樣的差異&#34;&gt;請說明單點播送與群播網路寬頻上的運用有什麼樣的差異&lt;/h4&gt;
&lt;p&gt;單點播送在技術上，需要將兩台電腦的兩台主機 NLB 網路介面的 MAC 位址變成完全一樣，以至於讓兩台主機彼此無法互相連線。&lt;/p&gt;
&lt;p&gt;群播信息同時傳遞給一組目的地址。它使用策略是最高效的，因為消息在每條網絡線路上只需傳遞一次，而且只有在線路分叉的時候，消息才會被複製。&lt;/p&gt;
&lt;h4 id=&#34;群播的協定中為什麼需要路由的機制&#34;&gt;群播的協定中為什麼需要路由的機制？&lt;/h4&gt;
&lt;p&gt;群播使用的IP位址有特定的格式，所以一旦網路節點發現封包中有群播的位址，就會採用群播的處理方式，主要的問題是路由(routing)，支援群播的路由器透過IGMP提供的資訊來建立路由，群播路由的方法很多，包括PIM(Protocol Independent Multicast)、DVMRP(Distance-Vector Multicast Routing Protocol)、CBT(Core-Based Tree)與MOSPF(Multicast Open Shortest Path First)。群播路由還要考慮到用戶的分布狀況，所以有所謂的dense mode與sparse mode的情形，用戶所在的網域也是技術上考慮的因素之一&lt;/p&gt;
&lt;h4 id=&#34;請說明服務品質的協定與串流服務之間有何關聯&#34;&gt;請說明服務品質的協定與串流服務之間有何關聯？&lt;/h4&gt;
&lt;p&gt;為了能保證服務品質(QoS)，有幾個協定特別針對QoS的要求發展出來，其中RSVP可以在網路邊界(edge)預約資源、MPLS可以控制流量、DiffServ可以指定封包的優先順序。不過，萬一往來網路超載，這些協定還是起不了作用。&lt;/p&gt;
&lt;h4 id=&#34;是說明串流播放與下載播放的差別&#34;&gt;是說明串流播放與下載播放的差別？&lt;/h4&gt;
&lt;p&gt;串流可以試想為邊播放邊下載，它主要不同於下載播放為下載播放需要將檔案下載到電腦再進行播放，此特性使得檔案得以留存，但也會造成儲存空間的損耗。
串流的話，由於邊播放邊下載，因此不需要完全加載完畢才能觀看影片，也不會在本地端電腦將檔案留存，僅作為暫存形式存在。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;第4週視訊編碼與錯誤修復技術&#34;&gt;第4週：視訊編碼與錯誤修復技術&lt;/h2&gt;
&lt;h3 id=&#34;homework3&#34;&gt;HomeWork3&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/gdjSOqG.png&#34;
	width=&#34;1009&#34;
	height=&#34;676&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/gdjSOqG_hubf960300ce07de4080f8a37cb954950e_248100_480x0_resize_box_3.png 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/gdjSOqG_hubf960300ce07de4080f8a37cb954950e_248100_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;358px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;試著比較原始視訊內容與編碼過後視訊內容的差異&#34;&gt;試著比較原始視訊內容與編碼過後視訊內容的差異?&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;編碼的轉換過程中，會有視訊失真的產生。&lt;/li&gt;
&lt;li&gt;編碼後整體的位元總數減少。&lt;/li&gt;
&lt;li&gt;空間域轉換成頻率域。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;為什麼要做視訊編碼&#34;&gt;為什麼要做視訊編碼?&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;原始視訊內容與編碼過後視訊內容的差異，絕大多數的應用無法處理如此龐大的資料量。&lt;/li&gt;
&lt;li&gt;原始的視訊內容儲存起來需要很大的儲存空間。所以必須編碼減少儲存空間負擔。&lt;/li&gt;
&lt;li&gt;網路的傳輸能力有限，所以必須編碼減少儲存傳輸負擔。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;請比較ip與b-frame之間的差異與特性&#34;&gt;請比較I、P與B frame之間的差異與特性。&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;I Frame 必須要存在的Frame，資料量最大，不需要去參考其他的畫面，沒有I Frame則無法重組GOP。&lt;/li&gt;
&lt;li&gt;P Frame 資料量次中，必須參考I Frame，從鄰近解出來的I Frame所加上差異部分的畫面。&lt;/li&gt;
&lt;li&gt;B Frame 資料量最小，畫質最差，必須參考I Frame與P Frame，然後加上差異部分的畫面。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;何謂spatial與temporal-redundancy&#34;&gt;何謂Spatial與Temporal Redundancy?&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Temporal：在視訊資料中，相鄰的影格（frame）與影格之間通常有很強的關連性，這樣的關連性即為時間上的冗餘資訊。時間的冗餘部分，基本上只是稍微的移動而已，但是實際上的視訊大同小異。&lt;/li&gt;
&lt;li&gt;Spatial：在同一張影格之中，相鄰的像素之間通常有很強的關連性，這樣的關連性即為空間上的冗餘資訊。因為視訊中的每一個點與點之間，常常都是有相關性的，例如：一台車子的視訊，車子裡面的點與點之間，相對的點的顏色都是類似的。&lt;/li&gt;
&lt;li&gt;Statistical:統計上的冗餘資訊指的是欲編碼的符號（symbol）的機率分布是不均勻（non-uniform）的。&lt;/li&gt;
&lt;li&gt;perceptual:感知上的冗餘資訊是指在人在觀看視訊時，人眼無法察覺的資訊。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;編碼主要由哪三個步驟所組成並解釋說明&#34;&gt;『編碼』主要由哪三個步驟所組成?並解釋說明。&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;表示法(Representation)：濃縮成幾個重要訊息的參數。&lt;/li&gt;
&lt;li&gt;量化(Quantization)：離散參數。&lt;/li&gt;
&lt;li&gt;編碼(Binary encoding)：利用非等量化參數統計。&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;第5週視訊編碼與錯誤修復技術&#34;&gt;第5週：視訊編碼與錯誤修復技術&lt;/h2&gt;
&lt;h3 id=&#34;homework4&#34;&gt;HomeWork4&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/LLCB2gL.png&#34;
	width=&#34;883&#34;
	height=&#34;557&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/LLCB2gL_hu09a7f8de2c128c864d2cb2704e190e82_72040_480x0_resize_box_3.png 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/LLCB2gL_hu09a7f8de2c128c864d2cb2704e190e82_72040_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;158&#34;
		data-flex-basis=&#34;380px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;視訊編碼為什麼會廣泛在網路視訊串流普遍使用&#34;&gt;視訊編碼為什麼會廣泛在網路視訊串流普遍使用?&lt;/h4&gt;
&lt;p&gt;可高效率視訊壓縮可以為應用來來巨大的改變，解決了檔案大小跟網路速度不成比的差距讓影片圖片都可以快速的傳播，多了很多應用的空間，以至於人們現在隨時隨地都能掌握即時影音資訊&lt;/p&gt;
&lt;p&gt;應證了古人所說的一句話：秀才不出們便知天下事。&lt;/p&gt;
&lt;h4 id=&#34;說明解釋h263的階層式架構&#34;&gt;說明解釋H.263的階層式架構。&lt;/h4&gt;
&lt;p&gt;H.263以一種階層式的結構組成，由上而下依序分為Picture、Group of blocks(GOB)、Macroblock(MB)、Block四層&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Picture Layer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Group of blocks(GOB) Layer：主要是條列狀結構的Macroblock所組成，組成一組一組的GOB。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Macroblock Layer：一個Macroblock所涵蓋的區域是16 * 16 pixels，而一個Macroblock是由6個Block組成的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Block Layer：一個Block包含了 8 * 8 個pixels。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/GHk9lMW.jpg&#34;
	width=&#34;600&#34;
	height=&#34;353&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/GHk9lMW_hu3f2a162f79977b683e0ecdc2ed2ead55_16648_480x0_resize_q75_box.jpg 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/GHk9lMW_hu3f2a162f79977b683e0ecdc2ed2ead55_16648_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;169&#34;
		data-flex-basis=&#34;407px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;試著比較h261與h263的差異&#34;&gt;試著比較H.261與H.263的差異。&lt;/h4&gt;
&lt;p&gt;H.261的應用：用於面對面的可視電話和視頻會議。&lt;/p&gt;
&lt;p&gt;H.263的應用：H.263最初設計為基於H.324的系統進行傳輸（即基於公共交換電話網和其它基於電路交換的
網絡進行視頻會議和視頻電話）。&lt;/p&gt;
&lt;p&gt;H.261的概述：H.261是1990年ITU-T制定的一個視頻編碼標準，屬於視頻編解碼器。&lt;/p&gt;
&lt;p&gt;H.263的概述：H.263是由ITU-T制定的視頻會議用的低碼率視頻編碼標準，屬於視頻編解碼器。&lt;/p&gt;
&lt;p&gt;H.261的特點：H.261在實時編碼時比MPEG所佔用的CPU運算量少得多，此算法為了優化帶寬佔用量，引進了在圖像質量與運動幅度之間的平衡折中機制，也就是說，劇烈運動的圖像比相對靜止的圖像質量要差。&lt;/p&gt;
&lt;p&gt;H.263的特點：H.263的運動補償使用半像素精度，而H.261則用全像素精度和環路濾波；數據流層次結構的某些部分在H.263中是可選的，使得編解碼可以配置成更低的數據率或更好的糾錯能力；H.263包含四個可協商的選項以改善性能；H.263採用無限制的運動向量以及基於語法的算術編碼。&lt;/p&gt;
&lt;p&gt;H.263的Motion compensation的精準度可以達到半個像點(Half-pixel accuracy)；
這種方式與 MPEG 使用的方式互相類似，主要是因為人類眼睛視覺的特性，讓我們
可以利用這種方法將位移估計的準確度提高。所以可以利用影像在時間上的相
關性來把影像作更多壓縮。相較於H.261卻只有整數個像點((Integer-pixel accuracy)
可重疊式區塊位移補償(Overlapped block motion compensation, OBMC)：利用移位估計找出最相似的Block之後，傳統的方法就直接把這些Block覆蓋上去，再加上估計的誤差值就形成了目前的影像。
但是相對的在H.263中，所有目前的Block都會是三個Block的加權平均值再加上誤差值，然而裡面的三個Block都會有相鄰的關係。所以在Block的大小從原本的16x16變成8x8。所以會讓壓縮過後的影像品質更好，而且還能保值較佳的壓縮比例。&lt;/p&gt;
&lt;h4 id=&#34;h263相較於h261&#34;&gt;H.263相較於H.261&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;減少了許多成本&lt;/li&gt;
&lt;li&gt;支援了更多的視訊格式&lt;/li&gt;
&lt;li&gt;提供Overlapped block motion compensation (OBMC)。&lt;/li&gt;
&lt;li&gt;利用新的Arithmetic coding&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;h264svc視訊品質分成三種可調方式&#34;&gt;H.264/SVC視訊品質分成三種可調方式：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;SNR scalability&lt;/li&gt;
&lt;li&gt;Temporal scalability&lt;/li&gt;
&lt;li&gt;Spatial scalability&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;比較h264svc與avc的差異&#34;&gt;比較H.264/SVC與AVC的差異&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;傳統視訊協議 (H.264/AVC)&lt;/th&gt;
&lt;th&gt;Vidyo視訊協議 (H.264/SVC)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;視訊會議可以容忍的網路丟包率&lt;/td&gt;
&lt;td&gt;&amp;lt; 2 – 3 %&lt;/td&gt;
&lt;td&gt;&amp;lt;20%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;對網路的要求&lt;/td&gt;
&lt;td&gt;專線&lt;/td&gt;
&lt;td&gt;共享線路&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;視訊會議延遲&lt;/td&gt;
&lt;td&gt;400毫秒&lt;/td&gt;
&lt;td&gt;&amp;lt; 200毫秒&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;視訊會議效果&lt;/td&gt;
&lt;td&gt;非實時互動&lt;/td&gt;
&lt;td&gt;實時互動&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HD 會議室型終端的開銷&lt;/td&gt;
&lt;td&gt;昂貴&lt;/td&gt;
&lt;td&gt;普及型&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;AVC實際上是H.264協議的別名。但自從H.264協議中增加了SVC的部分之後，人們習慣將不包含 SVC 的 H.264協議那一部分稱為AVC，而將 SVC 這一部分單獨稱為SVC。
H.264 SVC（H.264可分級編碼）作為H.264標準的一個擴充套件最初由JVT在2004年開始制定，並於2007年7月獲得ITU批准。H.264 SVC以H.264 AVC視訊編解碼器標準為基礎，利用了AVC編解碼器的各種高效演算法工具，在編碼產生的編碼視訊時間上（幀率）、空間上（解析度）可擴充套件，並且是在視訊質 量方面可擴充套件的，可產生不同幀速率、解析度或質量等級的解碼視訊。可進行視訊品質的調整。視訊編碼品質較佳。可使用單一或多個bit stream。網路適應性較佳。
AVC在網路傳輸品質較差時，並無法即時撥放視訊視訊，相對的SVC可以用較低的視訊品質進行播放的動作，雖然無法提供高品質的視訊，但是提升了視訊串流的流暢性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;第8週視訊編碼與錯誤修復技術&#34;&gt;第8週：視訊編碼與錯誤修復技術&lt;/h2&gt;
&lt;h3 id=&#34;homework5&#34;&gt;HomeWork5&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/qvSfZ3L.png&#34;
	width=&#34;762&#34;
	height=&#34;556&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/qvSfZ3L_hu00a0dd7ade069720994f5cd482ac49b5_72388_480x0_resize_box_3.png 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/qvSfZ3L_hu00a0dd7ade069720994f5cd482ac49b5_72388_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;137&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;網路視訊串流中arq與fec兩種錯誤回覆機制哪種比較合適&#34;&gt;網路視訊串流中，ARQ與FEC兩種錯誤回覆機制哪種比較合適？&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;必須使用FEC，因為當發現錯誤時，使用ARQ機制原始資料已不再可用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;請說明arq的運作方式&#34;&gt;請說明ARQ的運作方式&lt;/h4&gt;
&lt;p&gt;ANS：當Server與Client端要傳送資料的時候，如果訊息在傳輸的過程當中發生了錯誤，接收端會回覆傳送端，而常見的方法有以下三種：
Stop-and-wait Automatic Repeat Request:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;發送端每傳送一筆資料封包就先暫時停下來，待其收到接收端(Receiver)傳回的ACK/NACK，或者在特定時間後尚未收到ACK/NACK時才決定傳新資料/重傳。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/q1N0Z1u.jpg&#34;
	width=&#34;500&#34;
	height=&#34;240&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/q1N0Z1u_hud25a4271c4de0ab8bdca6bdb972a3931_25374_480x0_resize_q75_box.jpg 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/q1N0Z1u_hud25a4271c4de0ab8bdca6bdb972a3931_25374_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;208&#34;
		data-flex-basis=&#34;500px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Go-back N Automatic Repeat Request:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;發送端持續不斷地傳送資料封包，若收到ACK時不改變其動作，但收到NACK時會跳回錯誤的資料封包再依序重傳一次。接收端在回傳NACK後便捨棄接下來收到的封包，待前一次傳錯的資料正確解碼(接收)後，才開始繼續依序儲存資料封包。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/YSNb2lh.jpg&#34;
	width=&#34;500&#34;
	height=&#34;246&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/YSNb2lh_hud25a4271c4de0ab8bdca6bdb972a3931_35336_480x0_resize_q75_box.jpg 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/YSNb2lh_hud25a4271c4de0ab8bdca6bdb972a3931_35336_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;203&#34;
		data-flex-basis=&#34;487px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Select Repeat Automatic Repeat Request:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;做法與Go-back-N ARQ相似，但收到NACK時僅重傳錯誤的那份資料封包，而非重新依序重傳，另外，接收端在回傳NACK後並非捨棄接下來收到的封包而是存在緩衝器(Buffer)，待資料全部接收(正確解碼)完成後再重新依序排列。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/jEDXjhF.jpg&#34;
	width=&#34;500&#34;
	height=&#34;269&#34;
	srcset=&#34;https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/jEDXjhF_hud25a4271c4de0ab8bdca6bdb972a3931_38992_480x0_resize_q75_box.jpg 480w, https://tsairongfu.github.io/zh-tw/p/%E9%80%9A%E8%A8%8A%E7%B6%B2%E8%B7%AF%E8%88%87%E5%A4%9A%E5%AA%92%E9%AB%94%E6%87%89%E7%94%A8/jEDXjhF_hud25a4271c4de0ab8bdca6bdb972a3931_38992_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;185&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;請說明fec的運作方式&#34;&gt;請說明FEC的運作方式？&lt;/h4&gt;
&lt;p&gt;ANS：基本的FEC傳送運作，Server欲傳送k bytes資料時，它會先經由FEC encoder進行編碼動作，產生(n-k)=h bytes連同原始資料k bytes一起傳送出去，並且允許發生h bytes的loss或error，當傳輸的過程中若發生錯誤時，client端可已經由FEC decoder利用所接收到的k bytes進行資料解碼，如果錯誤發生的範圍在h bytes錯誤內，就可將錯誤的資料修復回來，並重新建構原始的資料。&lt;/p&gt;
&lt;h4 id=&#34;試著比較arq與fec兩種錯誤回覆機制的差異&#34;&gt;試著比較ARQ與FEC兩種錯誤回覆機制的差異？&lt;/h4&gt;
&lt;p&gt;ANS：Automatic Repeat-reQuest
做法：
當資料遺失時，則要求重新傳送未收到的資料。
優點：
只需重送遺失的資料。
缺點：
時效性與大量遺失頻寬消耗。
Forward Error Correction
做法：
加上些許額外的資訊，當接收端接收的資料不完整時，可以透過額外的資訊來修復與還原。&lt;/p&gt;
&lt;p&gt;優點：
不需要仰賴server重送即可逕行修復部分錯誤。&lt;/p&gt;
&lt;p&gt;缺點：
耗費額外的頻寬與資源。&lt;/p&gt;
&lt;h4 id=&#34;請解釋packet-leavel-fec與byte-leavel-fec的差異&#34;&gt;請解釋Packet-Leavel FEC與Byte Leavel FEC的差異？&lt;/h4&gt;
&lt;p&gt;ANS：Byte-level FEC為correcting codes，通常使用在physical layer，FEC(n, k)中n為block size，表示包含k個message symbols與n-k個parity symbols提供解碼端進行錯誤的修正，一個symbol對應一組bit sequence(如byte)，因無法知道到底有哪些symbols發生了error，所以correcting codes最多只能修復(n-k)/2個symbol錯誤。一般的correcting codes無法抵抗大量error burst的發生，所以通常會搭配interleaving的方式傳送，為的就是要將錯誤分散而減少burst所造成的影響。
Packet-level FEC為erasure codes，通常使用在Transport或Application layer，FEC(n, k)中n為block size，包含k個data packets與n-k個parity packets，因為在IP層以上我們可以知道到底有哪些packets發生了error，所以我們採用erasure codes，也就是假設MH可以正確的接收到n個packets中的任何k個packets，任何遺失的data packets將可以正確的被重建回來。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
